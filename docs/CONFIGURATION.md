# Go Logger é…ç½®æŒ‡å—

## ç›®å½•

- [ğŸ”§ åŸºç¡€é…ç½®](#-åŸºç¡€é…ç½®)
- [âš™ï¸ é…ç½®ç»“æ„](#ï¸-é…ç½®ç»“æ„)
- [ğŸŒ ç¯å¢ƒé…ç½®](#-ç¯å¢ƒé…ç½®)
- [ğŸ“ é…ç½®æ–‡ä»¶](#-é…ç½®æ–‡ä»¶)
- [ğŸ”„ åŠ¨æ€é…ç½®](#-åŠ¨æ€é…ç½®)
- [ğŸ“Š ç›‘æ§é…ç½®](#-ç›‘æ§é…ç½®)
- [ğŸ¯ æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)

## ğŸ”§ åŸºç¡€é…ç½®

### å¿«é€Ÿé…ç½®

```go
// æœ€ç®€é…ç½®
logger := logger.New()

// åŸºç¡€é…ç½®
config := &Config{
    Level:      INFO,
    Output:     os.Stdout,
    TimeFormat: TimeFormatStandard,
    Colorful:   true,
}
logger := logger.NewWithConfig(config)
```

### æ€§èƒ½é…ç½®

```go
// é«˜æ€§èƒ½é…ç½®
config := &Config{
    Level:      INFO,
    TimeFormat: TimeFormatDisabled, // ç¦ç”¨æ—¶é—´æˆ³è·å¾—æœ€é«˜æ€§èƒ½
    AsyncWrite: true,               // å¼‚æ­¥å†™å…¥
    BufferSize: 8192,              // ç¼“å†²åŒºå¤§å°
    PoolSize:   10,                // å¯¹è±¡æ± å¤§å°
}

// æè‡´æ€§èƒ½é…ç½®
ultraConfig := &UltraFastConfig{
    Level:      INFO,
    TimeFormat: TimeFormatDisabled,
    Colorful:   false,
    SyncMode:   true,
}
```

### è°ƒç”¨è€…ä¿¡æ¯é…ç½®

`ShowCaller` åŠŸèƒ½å…è®¸æ‚¨åœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºè°ƒç”¨è€…ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶åå’Œè¡Œå·ï¼Œè¿™å¯¹è°ƒè¯•éå¸¸æœ‰ç”¨ã€‚

```go
// å¯ç”¨è°ƒç”¨è€…ä¿¡æ¯
adapter, _ := logger.NewStandardAdapter(&logger.AdapterConfig{
    Type:       logger.StandardAdapter,
    Level:      logger.DEBUG,
    Output:     os.Stdout,
    ShowCaller: true,  // å¯ç”¨è°ƒç”¨è€…ä¿¡æ¯æ˜¾ç¤º
    Colorful:   true,
})

// ç¦ç”¨è°ƒç”¨è€…ä¿¡æ¯
adapter, _ := logger.NewStandardAdapter(&logger.AdapterConfig{
    Type:       logger.StandardAdapter,
    Level:      logger.INFO,
    Output:     os.Stdout,
    ShowCaller: false, // ç¦ç”¨è°ƒç”¨è€…ä¿¡æ¯æ˜¾ç¤º
    Colorful:   true,
})
```

**è¾“å‡ºæ•ˆæœå¯¹æ¯”ï¼š**

å¯ç”¨ `ShowCaller: true`ï¼š
```
2025/11/22 13:19:09 ğŸ› [DEBUG] [standard_adapter.go:120:Debug] æ˜¾ç¤ºè°ƒç”¨è€…ä¿¡æ¯çš„æ—¥å¿—
2025/11/22 13:19:09 â„¹ï¸ [INFO] [standard_adapter.go:127:Info] æ–‡ä»¶åå’Œè¡Œå·ä¼šæ˜¾ç¤ºåœ¨æ—¥å¿—ä¸­
```

ç¦ç”¨ `ShowCaller: false`ï¼š
```
2025/11/22 13:19:09 ğŸ› [DEBUG] ä¸æ˜¾ç¤ºè°ƒç”¨è€…ä¿¡æ¯çš„æ—¥å¿—
2025/11/22 13:19:09 â„¹ï¸ [INFO] æ²¡æœ‰æ–‡ä»¶åå’Œè¡Œå·ä¿¡æ¯
```

**æ€§èƒ½å»ºè®®ï¼š**
- å¼€å‘ç¯å¢ƒï¼šå»ºè®®å¯ç”¨ `ShowCaller: true` ä»¥ä¾¿è°ƒè¯•
- ç”Ÿäº§ç¯å¢ƒï¼šå»ºè®®ç¦ç”¨ `ShowCaller: false` ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½

## âš™ï¸ é…ç½®ç»“æ„

### å®Œæ•´é…ç½®ç»“æ„

```go
type Config struct {
    // åŸºç¡€è®¾ç½®
    Level       LogLevel      `json:"level" yaml:"level"`
    Output      io.Writer     `json:"-" yaml:"-"`
    TimeFormat  TimeFormat    `json:"time_format" yaml:"time_format"`
    Colorful    bool          `json:"colorful" yaml:"colorful"`
    
    // æ€§èƒ½è®¾ç½®
    BufferSize     int  `json:"buffer_size" yaml:"buffer_size"`
    AsyncWrite     bool `json:"async_write" yaml:"async_write"`
    PoolSize       int  `json:"pool_size" yaml:"pool_size"`
    BatchSize      int  `json:"batch_size" yaml:"batch_size"`
    BatchTimeout   time.Duration `json:"batch_timeout" yaml:"batch_timeout"`
    
    // ä¼ä¸šåŠŸèƒ½
    EnableMemoryStats  bool `json:"enable_memory_stats" yaml:"enable_memory_stats"`
    EnableDistributed  bool `json:"enable_distributed" yaml:"enable_distributed"`
    EnableMetrics      bool `json:"enable_metrics" yaml:"enable_metrics"`
    EnableHooks        bool `json:"enable_hooks" yaml:"enable_hooks"`
    
    // è¾“å‡ºæ ¼å¼
    Format         FormatType `json:"format" yaml:"format"`
    TimestampKey   string     `json:"timestamp_key" yaml:"timestamp_key"`
    LevelKey       string     `json:"level_key" yaml:"level_key"`
    MessageKey     string     `json:"message_key" yaml:"message_key"`
    CallerKey      string     `json:"caller_key" yaml:"caller_key"`
    StacktraceKey  string     `json:"stacktrace_key" yaml:"stacktrace_key"`
    
    // å­—æ®µè®¾ç½®
    Fields         map[string]interface{} `json:"fields" yaml:"fields"`
    ContextFields  []string              `json:"context_fields" yaml:"context_fields"`
    
    // è°ƒç”¨è€…ä¿¡æ¯é…ç½®
    ShowCaller     bool `json:"show_caller" yaml:"show_caller"`         // æ˜¾ç¤ºè°ƒç”¨è€…ä¿¡æ¯ï¼ˆæ–‡ä»¶åå’Œè¡Œå·ï¼‰
    CallerDepth    int  `json:"caller_depth" yaml:"caller_depth"`       // è°ƒç”¨è€…æ·±åº¦ï¼ˆé»˜è®¤ï¼š2ï¼‰
    ShowStacktrace bool `json:"show_stacktrace" yaml:"show_stacktrace"` // æ˜¾ç¤ºå †æ ˆè·Ÿè¸ªï¼ˆä»…é”™è¯¯æ—¥å¿—ï¼‰
    
    // ç»„ä»¶é…ç½®
    Adapters    []AdapterConfig    `json:"adapters" yaml:"adapters"`
    Hooks       []HookConfig       `json:"hooks" yaml:"hooks"`
    Middlewares []MiddlewareConfig `json:"middlewares" yaml:"middlewares"`
    
    // ç›‘æ§é…ç½®
    Monitoring MonitoringConfig `json:"monitoring" yaml:"monitoring"`
}
```

### é€‚é…å™¨é…ç½®

```go
type AdapterConfig struct {
    Name     string      `json:"name" yaml:"name"`
    Type     string      `json:"type" yaml:"type"`
    Level    LogLevel    `json:"level" yaml:"level"`
    Enabled  bool        `json:"enabled" yaml:"enabled"`
    Config   interface{} `json:"config" yaml:"config"`
}

// æ§åˆ¶å°é€‚é…å™¨é…ç½®
type ConsoleAdapterConfig struct {
    Level         LogLevel    `json:"level" yaml:"level"`
    Colorful      bool        `json:"colorful" yaml:"colorful"`
    Format        FormatType  `json:"format" yaml:"format"`
    TimeFormat    TimeFormat  `json:"time_format" yaml:"time_format"`
    ShowCaller    bool        `json:"show_caller" yaml:"show_caller"` // æ˜¾ç¤ºè°ƒç”¨è€…ä¿¡æ¯ï¼ˆæ–‡ä»¶å:.è¡Œå·ï¼‰
    CallerDepth   int         `json:"caller_depth" yaml:"caller_depth"`
}

// æ–‡ä»¶é€‚é…å™¨é…ç½®
type FileAdapterConfig struct {
    Level           LogLevel      `json:"level" yaml:"level"`
    Path            string        `json:"path" yaml:"path"`
    MaxSize         int64         `json:"max_size" yaml:"max_size"`
    MaxFiles        int           `json:"max_files" yaml:"max_files"`
    MaxAge          time.Duration `json:"max_age" yaml:"max_age"`
    Compress        bool          `json:"compress" yaml:"compress"`
    Format          FormatType    `json:"format" yaml:"format"`
    AsyncWrite      bool          `json:"async_write" yaml:"async_write"`
    BufferSize      int           `json:"buffer_size" yaml:"buffer_size"`
    FlushInterval   time.Duration `json:"flush_interval" yaml:"flush_interval"`
    FlushThreshold  int           `json:"flush_threshold" yaml:"flush_threshold"`
}

// ç½‘ç»œé€‚é…å™¨é…ç½®
type NetworkAdapterConfig struct {
    Level            LogLevel      `json:"level" yaml:"level"`
    Protocol         string        `json:"protocol" yaml:"protocol"` // tcp, udp, http
    Address          string        `json:"address" yaml:"address"`
    Timeout          time.Duration `json:"timeout" yaml:"timeout"`
    MaxConnections   int           `json:"max_connections" yaml:"max_connections"`
    MaxIdleTime      time.Duration `json:"max_idle_time" yaml:"max_idle_time"`
    BatchSize        int           `json:"batch_size" yaml:"batch_size"`
    BatchTimeout     time.Duration `json:"batch_timeout" yaml:"batch_timeout"`
    Compression      string        `json:"compression" yaml:"compression"`
    CompressionLevel int           `json:"compression_level" yaml:"compression_level"`
    MaxRetries       int           `json:"max_retries" yaml:"max_retries"`
    RetryDelay       time.Duration `json:"retry_delay" yaml:"retry_delay"`
    BackoffFactor    float64       `json:"backoff_factor" yaml:"backoff_factor"`
}
```

### ç›‘æ§é…ç½®

```go
type MonitoringConfig struct {
    Memory      MemoryMonitoringConfig      `json:"memory" yaml:"memory"`
    Performance PerformanceMonitoringConfig `json:"performance" yaml:"performance"`
    IO          IOMonitoringConfig          `json:"io" yaml:"io"`
}

type MemoryMonitoringConfig struct {
    Enabled         bool          `json:"enabled" yaml:"enabled"`
    Threshold       float64       `json:"threshold" yaml:"threshold"`
    SampleInterval  time.Duration `json:"sample_interval" yaml:"sample_interval"`
    LeakDetection   bool          `json:"leak_detection" yaml:"leak_detection"`
    MaxHistorySize  int           `json:"max_history_size" yaml:"max_history_size"`
    GCPercent       int           `json:"gc_percent" yaml:"gc_percent"`
    MaxMemory       int64         `json:"max_memory" yaml:"max_memory"`
}

type PerformanceMonitoringConfig struct {
    Enabled             bool          `json:"enabled" yaml:"enabled"`
    LatencyThreshold    time.Duration `json:"latency_threshold" yaml:"latency_threshold"`
    ThroughputThreshold float64       `json:"throughput_threshold" yaml:"throughput_threshold"`
    SampleRate          float64       `json:"sample_rate" yaml:"sample_rate"`
}
```

## ğŸŒ ç¯å¢ƒé…ç½®

### å¼€å‘ç¯å¢ƒ

```go
func NewDevelopmentConfig() *Config {
    return &Config{
        Level:      DEBUG,
        Output:     os.Stdout,
        Colorful:   true,
        TimeFormat: TimeFormatShort,
        Format:     FormatText,
        ShowCaller: true,
        
        // å¼€å‘ç¯å¢ƒä¸éœ€è¦é«˜æ€§èƒ½ä¼˜åŒ–
        AsyncWrite: false,
        BufferSize: 0,
        
        // å¯ç”¨è¯¦ç»†ç›‘æ§
        EnableMemoryStats: true,
        EnableMetrics:     true,
        
        Fields: map[string]interface{}{
            "env":     "development",
            "service": "my-app",
            "version": "dev",
        },
        
        Adapters: []AdapterConfig{
            {
                Name:    "console",
                Type:    "console",
                Level:   DEBUG,
                Enabled: true,
                Config: &ConsoleAdapterConfig{
                    Colorful: true,
                    Format:   FormatText,
                },
            },
        },
        
        Monitoring: MonitoringConfig{
            Memory: MemoryMonitoringConfig{
                Enabled:        true,
                Threshold:      90.0,
                SampleInterval: time.Second * 5,
            },
        },
    }
}
```

### æµ‹è¯•ç¯å¢ƒ

```go
func NewTestingConfig() *Config {
    return &Config{
        Level:      INFO,
        Output:     os.Stdout,
        Colorful:   false,
        TimeFormat: TimeFormatRFC3339,
        Format:     FormatJSON,
        ShowCaller: false,
        
        // æµ‹è¯•ç¯å¢ƒä½¿ç”¨å†…å­˜é€‚é…å™¨
        Adapters: []AdapterConfig{
            {
                Name:    "memory",
                Type:    "memory",
                Level:   DEBUG,
                Enabled: true,
                Config: &MemoryAdapterConfig{
                    MaxSize: 1000,
                    Format:  FormatJSON,
                },
            },
        },
        
        // ç¦ç”¨ä¸€äº›ç›‘æ§åŠŸèƒ½
        EnableMemoryStats: false,
        EnableMetrics:     false,
        
        Fields: map[string]interface{}{
            "env":     "testing",
            "service": "my-app",
            "version": "test",
        },
    }
}
```

### ç”Ÿäº§ç¯å¢ƒ

```go
func NewProductionConfig() *Config {
    return &Config{
        Level:      INFO,
        Output:     os.Stdout,
        Colorful:   false,
        TimeFormat: TimeFormatRFC3339,
        Format:     FormatJSON,
        ShowCaller: false,
        
        // ç”Ÿäº§ç¯å¢ƒé«˜æ€§èƒ½é…ç½®
        AsyncWrite:   true,
        BufferSize:   8192,
        PoolSize:     10,
        BatchSize:    100,
        BatchTimeout: time.Millisecond * 100,
        
        // å¯ç”¨ä¼ä¸šåŠŸèƒ½
        EnableMemoryStats: true,
        EnableDistributed: true,
        EnableMetrics:     true,
        EnableHooks:       true,
        
        Fields: map[string]interface{}{
            "env":     "production",
            "service": "my-app",
            "version": "1.0.0",
        },
        
        ContextFields: []string{
            "trace_id",
            "user_id",
            "session_id",
            "tenant_id",
        },
        
        Adapters: []AdapterConfig{
            // æ–‡ä»¶é€‚é…å™¨
            {
                Name:    "file",
                Type:    "file",
                Level:   INFO,
                Enabled: true,
                Config: &FileAdapterConfig{
                    Path:           "/var/log/app.log",
                    MaxSize:        100 * 1024 * 1024, // 100MB
                    MaxFiles:       10,
                    MaxAge:         30 * 24 * time.Hour, // 30å¤©
                    Compress:       true,
                    AsyncWrite:     true,
                    BufferSize:     4096,
                    FlushInterval:  time.Second * 5,
                    FlushThreshold: 1000,
                },
            },
            
            // Elasticsearché€‚é…å™¨
            {
                Name:    "elasticsearch",
                Type:    "elasticsearch",
                Level:   WARN,
                Enabled: true,
                Config: &ElasticsearchAdapterConfig{
                    URLs:          []string{"http://es:9200"},
                    Index:         "logs-2024",
                    BufferSize:    1000,
                    FlushInterval: time.Second * 30,
                },
            },
        },
        
        Hooks: []HookConfig{
            // PrometheusæŒ‡æ ‡é’©å­
            {
                Name:    "metrics",
                Type:    "prometheus",
                Enabled: true,
                Config: &PrometheusHookConfig{
                    Endpoint: "/metrics",
                    Namespace: "app",
                },
            },
            
            // å‘Šè­¦é’©å­
            {
                Name:    "alert",
                Type:    "webhook",
                Enabled: true,
                Config: &WebhookHookConfig{
                    URL:    "http://alert:8080/webhook",
                    Levels: []LogLevel{ERROR, FATAL},
                },
            },
        },
        
        Monitoring: MonitoringConfig{
            Memory: MemoryMonitoringConfig{
                Enabled:         true,
                Threshold:       85.0,
                SampleInterval:  time.Second * 5,
                LeakDetection:   true,
                MaxHistorySize:  100,
                GCPercent:       75,
                MaxMemory:       4 * 1024 * 1024 * 1024, // 4GB
            },
            Performance: PerformanceMonitoringConfig{
                Enabled:             true,
                LatencyThreshold:    time.Millisecond * 100,
                ThroughputThreshold: 1000.0,
                SampleRate:          0.1, // 10%é‡‡æ ·
            },
        },
    }
}
```

## ğŸ“ é…ç½®æ–‡ä»¶

### YAML é…ç½®æ–‡ä»¶

```yaml
# config/logger.yaml
logger:
  # åŸºç¡€è®¾ç½®
  level: info
  format: json
  time_format: rfc3339
  colorful: false
  show_caller: false
  
  # æ€§èƒ½è®¾ç½®
  async_write: true
  buffer_size: 8192
  pool_size: 10
  batch_size: 100
  batch_timeout: 100ms
  
  # ä¼ä¸šåŠŸèƒ½
  enable_memory_stats: true
  enable_distributed: true
  enable_metrics: true
  enable_hooks: true
  
  # å…¨å±€å­—æ®µ
  fields:
    service: "my-app"
    version: "1.2.0"
    environment: "production"
    datacenter: "us-west-2"
  
  # ä¸Šä¸‹æ–‡å­—æ®µ
  context_fields:
    - trace_id
    - span_id
    - user_id
    - session_id
    - tenant_id
    - correlation_id
  
  # é€‚é…å™¨é…ç½®
  adapters:
    - name: console
      type: console
      level: debug
      enabled: false  # ç”Ÿäº§ç¯å¢ƒç¦ç”¨æ§åˆ¶å°è¾“å‡º
      config:
        colorful: true
        format: text
        show_caller: true
        
    - name: file
      type: file
      level: info
      enabled: true
      config:
        path: "/var/log/app.log"
        max_size: 100MB
        max_files: 10
        max_age: 720h  # 30å¤©
        compress: true
        async_write: true
        buffer_size: 4096
        flush_interval: 5s
        flush_threshold: 1000
        
    - name: elasticsearch
      type: elasticsearch
      level: warn
      enabled: true
      config:
        urls: 
          - "http://es1:9200"
          - "http://es2:9200"
        index: "logs-2024"
        type: "_doc"
        buffer_size: 1000
        flush_interval: 30s
        username: "elastic"
        password: "password"
        
    - name: kafka
      type: kafka
      level: error
      enabled: true
      config:
        brokers:
          - "kafka1:9092"
          - "kafka2:9092"
        topic: "error-logs"
        partition: -1
        compression: "gzip"
  
  # é’©å­é…ç½®
  hooks:
    - name: metrics
      type: prometheus
      enabled: true
      config:
        endpoint: "/metrics"
        namespace: "app"
        subsystem: "logger"
        
    - name: alert
      type: webhook
      enabled: true
      config:
        url: "http://alert:8080/webhook"
        timeout: 10s
        levels: [error, fatal]
        batch_size: 10
        batch_timeout: 30s
        
    - name: audit
      type: audit
      enabled: true
      config:
        output: "/var/log/audit.log"
        levels: [info, warn, error, fatal]
  
  # ç›‘æ§é…ç½®
  monitoring:
    memory:
      enabled: true
      threshold: 85.0
      sample_interval: 5s
      leak_detection: true
      max_history_size: 100
      gc_percent: 75
      max_memory: 4GB
      
    performance:
      enabled: true
      latency_threshold: 100ms
      throughput_threshold: 1000.0
      sample_rate: 0.1
      
    io:
      enabled: true
      disk_usage_threshold: 80.0
      iops_threshold: 1000
      latency_threshold: 100ms
```

### JSON é…ç½®æ–‡ä»¶

```json
{
  "logger": {
    "level": "info",
    "format": "json",
    "time_format": "rfc3339",
    "colorful": false,
    "async_write": true,
    "buffer_size": 8192,
    "pool_size": 10,
    "enable_memory_stats": true,
    "enable_distributed": true,
    "enable_metrics": true,
    "fields": {
      "service": "my-app",
      "version": "1.2.0",
      "environment": "production"
    },
    "adapters": [
      {
        "name": "file",
        "type": "file",
        "level": "info",
        "enabled": true,
        "config": {
          "path": "/var/log/app.log",
          "max_size": 104857600,
          "max_files": 10,
          "compress": true
        }
      }
    ],
    "monitoring": {
      "memory": {
        "enabled": true,
        "threshold": 85.0,
        "sample_interval": "5s"
      }
    }
  }
}
```

### åŠ è½½é…ç½®æ–‡ä»¶

```go
// ä»YAMLæ–‡ä»¶åŠ è½½
config, err := logger.LoadConfigFromYAML("config/logger.yaml")
if err != nil {
    log.Fatal("åŠ è½½YAMLé…ç½®å¤±è´¥:", err)
}

// ä»JSONæ–‡ä»¶åŠ è½½
config, err := logger.LoadConfigFromJSON("config/logger.json")
if err != nil {
    log.Fatal("åŠ è½½JSONé…ç½®å¤±è´¥:", err)
}

// è‡ªåŠ¨æ£€æµ‹æ ¼å¼
config, err := logger.LoadConfigFromFile("config/logger.yaml")
if err != nil {
    log.Fatal("åŠ è½½é…ç½®å¤±è´¥:", err)
}

// åˆ›å»ºlogger
log, err := logger.NewWithConfig(config)
if err != nil {
    log.Fatal("åˆ›å»ºloggerå¤±è´¥:", err)
}
```

## ğŸ”„ åŠ¨æ€é…ç½®

### é…ç½®çƒ­é‡è½½

```go
// åˆ›å»ºé…ç½®ç®¡ç†å™¨
configManager := logger.NewConfigManager()

// ç›‘å¬é…ç½®æ–‡ä»¶å˜åŒ–
configManager.WatchFile("config/logger.yaml", func(newConfig *Config) {
    log.Info("æ£€æµ‹åˆ°é…ç½®å˜åŒ–ï¼Œæ­£åœ¨é‡æ–°åŠ è½½...")
    
    // éªŒè¯æ–°é…ç½®
    if err := newConfig.Validate(); err != nil {
        log.Error("æ–°é…ç½®éªŒè¯å¤±è´¥:", err)
        return
    }
    
    // åº”ç”¨æ–°é…ç½®
    if err := log.UpdateConfig(newConfig); err != nil {
        log.Error("é…ç½®æ›´æ–°å¤±è´¥:", err)
    } else {
        log.Info("é…ç½®æ›´æ–°æˆåŠŸ")
    }
})

// å¯åŠ¨é…ç½®ç›‘å¬
if err := configManager.Start(); err != nil {
    log.Fatal("å¯åŠ¨é…ç½®ç›‘å¬å¤±è´¥:", err)
}
defer configManager.Stop()
```

### HTTP API é…ç½®æ›´æ–°

```go
// é…ç½®æ›´æ–°API
http.HandleFunc("/admin/logger/config", func(w http.ResponseWriter, r *http.Request) {
    switch r.Method {
    case "GET":
        // è·å–å½“å‰é…ç½®
        currentConfig := log.GetConfig()
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(currentConfig)
        
    case "PUT":
        // æ›´æ–°é…ç½®
        var newConfig Config
        if err := json.NewDecoder(r.Body).Decode(&newConfig); err != nil {
            http.Error(w, "Invalid JSON: "+err.Error(), 400)
            return
        }
        
        // éªŒè¯é…ç½®
        if err := newConfig.Validate(); err != nil {
            http.Error(w, "Invalid config: "+err.Error(), 400)
            return
        }
        
        // åº”ç”¨é…ç½®
        if err := log.UpdateConfig(&newConfig); err != nil {
            http.Error(w, "Update failed: "+err.Error(), 500)
            return
        }
        
        w.WriteHeader(200)
        json.NewEncoder(w).Encode(map[string]string{"status": "updated"})
        
    case "PATCH":
        // éƒ¨åˆ†æ›´æ–°é…ç½®
        var updates map[string]interface{}
        if err := json.NewDecoder(r.Body).Decode(&updates); err != nil {
            http.Error(w, "Invalid JSON: "+err.Error(), 400)
            return
        }
        
        if err := log.UpdatePartialConfig(updates); err != nil {
            http.Error(w, "Update failed: "+err.Error(), 500)
            return
        }
        
        w.WriteHeader(200)
        json.NewEncoder(w).Encode(map[string]string{"status": "updated"})
    }
})
```

### è¿è¡Œæ—¶é…ç½®ä¿®æ”¹

```go
// ä¿®æ”¹æ—¥å¿—çº§åˆ«
log.SetLevel(DEBUG)

// ä¿®æ”¹é€‚é…å™¨é…ç½®
log.UpdateAdapterConfig("file", &FileAdapterConfig{
    Path:     "/tmp/debug.log",
    Level:    DEBUG,
    MaxSize:  50 * 1024 * 1024, // 50MB
    MaxFiles: 5,
})

// æ·»åŠ æ–°é€‚é…å™¨
newAdapter, err := logger.CreateAdapter("tcp", &TCPAdapterConfig{
    Level:   WARN,
    Address: "log-server:514",
    Format:  FormatJSON,
})
if err == nil {
    log.AddAdapter("tcp", newAdapter)
}

// ç§»é™¤é€‚é…å™¨
log.RemoveAdapter("console")

// å¯ç”¨/ç¦ç”¨é’©å­
log.EnableHook("alert")
log.DisableHook("metrics")

// ä¿®æ”¹ç›‘æ§é…ç½®
log.UpdateMonitoringConfig(&MonitoringConfig{
    Memory: MemoryMonitoringConfig{
        Enabled:   true,
        Threshold: 90.0, // æé«˜å†…å­˜é˜ˆå€¼
    },
})
```

## ğŸ“Š ç›‘æ§é…ç½®

### å†…å­˜ç›‘æ§é…ç½®

```go
memoryConfig := MemoryMonitoringConfig{
    Enabled:         true,
    Threshold:       85.0,                    // å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼
    SampleInterval:  time.Second * 5,         // é‡‡æ ·é—´éš”
    LeakDetection:   true,                    // å¯ç”¨æ³„æ¼æ£€æµ‹
    MaxHistorySize:  100,                     // å†å²è®°å½•æ•°é‡
    GCPercent:       75,                      // GCç™¾åˆ†æ¯”
    MaxMemory:       4 * 1024 * 1024 * 1024, // æœ€å¤§å†…å­˜é™åˆ¶
    
    // å›è°ƒé…ç½®
    OnThresholdExceeded: func(info *MemoryInfo) {
        // å†…å­˜é˜ˆå€¼è¶…å‡ºæ—¶çš„å¤„ç†
        log.Warn("å†…å­˜ä½¿ç”¨ç‡è¶…å‡ºé˜ˆå€¼", 
            "usage", info.MemoryUsage,
            "used", info.UsedMemory,
            "threshold", 85.0)
            
        // å¯ä»¥è§¦å‘å‘Šè­¦æˆ–æ¸…ç†æ“ä½œ
        if info.MemoryUsage > 90.0 {
            runtime.GC() // å¼ºåˆ¶GC
            log.Info("å¼ºåˆ¶æ‰§è¡ŒGC")
        }
    },
    
    OnLeakDetected: func(report *LeakReport) {
        // å†…å­˜æ³„æ¼æ£€æµ‹åˆ°æ—¶çš„å¤„ç†
        log.Error("æ£€æµ‹åˆ°å†…å­˜æ³„æ¼",
            "trend", report.GrowthTrend,
            "rate", report.MemoryGrowthRate,
            "risk", report.RiskLevel)
            
        // å‘é€å‘Šè­¦
        alertManager.SendAlert("memory_leak", report)
    },
}
```

### æ€§èƒ½ç›‘æ§é…ç½®

```go
performanceConfig := PerformanceMonitoringConfig{
    Enabled:             true,
    LatencyThreshold:    time.Millisecond * 100, // å»¶è¿Ÿé˜ˆå€¼
    ThroughputThreshold: 1000.0,                 // ååé‡é˜ˆå€¼
    SampleRate:          0.1,                    // 10%é‡‡æ ·ç‡
    
    // å›è°ƒé…ç½®
    OnLatencyExceeded: func(operation string, latency time.Duration) {
        log.Warn("æ“ä½œå»¶è¿Ÿè¶…æ ‡",
            "operation", operation,
            "latency", latency,
            "threshold", time.Millisecond*100)
    },
    
    OnThroughputExceeded: func(operation string, throughput float64) {
        log.Info("æ“ä½œååé‡è¶…æ ‡",
            "operation", operation,
            "throughput", throughput,
            "threshold", 1000.0)
    },
}
```

## ğŸ¯ æœ€ä½³å®è·µ

### é…ç½®åˆ†å±‚

```go
// åŸºç¡€é…ç½®
baseConfig := &Config{
    Level:      INFO,
    TimeFormat: TimeFormatRFC3339,
    Format:     FormatJSON,
}

// ç¯å¢ƒç‰¹å®šé…ç½®
var envConfig *Config
switch os.Getenv("ENVIRONMENT") {
case "development":
    envConfig = NewDevelopmentConfig()
case "staging":
    envConfig = NewStagingConfig()
case "production":
    envConfig = NewProductionConfig()
default:
    envConfig = NewDevelopmentConfig()
}

// åˆå¹¶é…ç½®
finalConfig := MergeConfigs(baseConfig, envConfig)
```

### é…ç½®éªŒè¯

```go
func (c *Config) Validate() error {
    // éªŒè¯åŸºç¡€è®¾ç½®
    if c.Level < 0 || c.Level > FATAL {
        return fmt.Errorf("invalid log level: %d", c.Level)
    }
    
    // éªŒè¯æ€§èƒ½è®¾ç½®
    if c.BufferSize < 0 {
        return fmt.Errorf("buffer size cannot be negative: %d", c.BufferSize)
    }
    
    if c.PoolSize < 0 {
        return fmt.Errorf("pool size cannot be negative: %d", c.PoolSize)
    }
    
    // éªŒè¯é€‚é…å™¨é…ç½®
    for i, adapter := range c.Adapters {
        if adapter.Name == "" {
            return fmt.Errorf("adapter[%d] name cannot be empty", i)
        }
        
        if adapter.Type == "" {
            return fmt.Errorf("adapter[%d] type cannot be empty", i)
        }
        
        // éªŒè¯é€‚é…å™¨ç‰¹å®šé…ç½®
        if err := ValidateAdapterConfig(adapter.Type, adapter.Config); err != nil {
            return fmt.Errorf("adapter[%d] config invalid: %v", i, err)
        }
    }
    
    return nil
}
```

### é…ç½®å®‰å…¨

```go
// æ•æ„Ÿä¿¡æ¯å¤„ç†
type SecureConfig struct {
    *Config
    
    // åŠ å¯†å­—æ®µ
    DatabasePassword string `json:"-" yaml:"-"` // ä¸åºåˆ—åŒ–
    APIKey          string `json:"-" yaml:"-"`
}

func (c *SecureConfig) LoadFromEnv() {
    // ä»ç¯å¢ƒå˜é‡åŠ è½½æ•æ„Ÿä¿¡æ¯
    c.DatabasePassword = os.Getenv("DB_PASSWORD")
    c.APIKey = os.Getenv("API_KEY")
}

func (c *SecureConfig) Sanitize() *Config {
    // è¿”å›ä¸åŒ…å«æ•æ„Ÿä¿¡æ¯çš„é…ç½®å‰¯æœ¬
    sanitized := *c.Config
    
    // æ¸…ç†æ•æ„Ÿå­—æ®µ
    if sanitized.Fields == nil {
        sanitized.Fields = make(map[string]interface{})
    }
    
    // ç§»é™¤æˆ–è„±æ•æ•æ„Ÿå­—æ®µ
    for key, value := range sanitized.Fields {
        if isSensitiveField(key) {
            sanitized.Fields[key] = "***" // è„±æ•å¤„ç†
        }
    }
    
    return &sanitized
}
```

### é…ç½®ä¼˜åŒ–

```go
// æ€§èƒ½ä¼˜åŒ–é…ç½®
func OptimizeForPerformance(config *Config) *Config {
    optimized := *config
    
    // æ ¹æ®ç³»ç»Ÿèµ„æºè°ƒæ•´é…ç½®
    numCPU := runtime.NumCPU()
    totalMemory := getTotalMemory()
    
    // è°ƒæ•´ç¼“å†²åŒºå¤§å°
    if totalMemory > 8*1024*1024*1024 { // 8GBä»¥ä¸Š
        optimized.BufferSize = 16384
        optimized.PoolSize = numCPU * 2
    } else if totalMemory > 4*1024*1024*1024 { // 4GBä»¥ä¸Š
        optimized.BufferSize = 8192
        optimized.PoolSize = numCPU
    } else {
        optimized.BufferSize = 4096
        optimized.PoolSize = numCPU / 2
        if optimized.PoolSize < 2 {
            optimized.PoolSize = 2
        }
    }
    
    // å¯ç”¨å¼‚æ­¥å†™å…¥ï¼ˆå¦‚æœæ”¯æŒï¼‰
    optimized.AsyncWrite = true
    
    // è°ƒæ•´æ‰¹å¤„ç†è®¾ç½®
    optimized.BatchSize = 100
    optimized.BatchTimeout = time.Millisecond * 100
    
    return &optimized
}

// å†…å­˜ä¼˜åŒ–é…ç½®
func OptimizeForMemory(config *Config) *Config {
    optimized := *config
    
    // å‡å°‘ç¼“å†²åŒºå¤§å°
    optimized.BufferSize = 1024
    optimized.PoolSize = 2
    
    // ç¦ç”¨ä¸€äº›å†…å­˜å¯†é›†å‹åŠŸèƒ½
    optimized.EnableMemoryStats = false
    optimized.EnableMetrics = false
    
    // å‡å°‘å†å²è®°å½•
    if optimized.Monitoring.Memory.MaxHistorySize > 10 {
        optimized.Monitoring.Memory.MaxHistorySize = 10
    }
    
    return &optimized
}
```

---

æ›´å¤šé…ç½®ç›¸å…³ä¿¡æ¯è¯·å‚è€ƒï¼š

- [ğŸ“š ä½¿ç”¨æŒ‡å—](USAGE.md) - å®Œæ•´ä½¿ç”¨æŒ‡å—
- [ğŸ“Š æ€§èƒ½è¯¦è§£](PERFORMANCE.md) - æ€§èƒ½é…ç½®ä¼˜åŒ–
- [ğŸ”„ è¿ç§»æŒ‡å—](MIGRATION.md) - é…ç½®è¿ç§»æŒ‡å—
- [ğŸ¯ Contextä½¿ç”¨æŒ‡å—](CONTEXT_USAGE.md) - åˆ†å¸ƒå¼é…ç½®